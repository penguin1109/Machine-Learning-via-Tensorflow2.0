{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Chorale Using RNN\n",
    "#### Sequence Data 분석하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. INFO\n",
    "- 바흐의 교향곡의 모든 382개의 합창곡으로 구성이 되어 있는 dataset이다.\n",
    "- 각 곡은 100개에서 640개의 time step의 길이를 가지고 있으며, 각 timestep은 4개의 정수를 담고 있다.\n",
    "- 각 정수는 피아노 음표의 인덱스에 해당하는데, 이번 노트북의 목표는 chorale의 time step sequence가 주어지면 다음 time step(4개의 음표)를 예측할 수 있는 \n",
    "    1. 순환 모델\n",
    "    2. 신겸망 모델 + 순환 모델  \n",
    "        - Wave Net\n",
    "        - LSTM\n",
    "        - GRU\n",
    "    을 만들 예정이다.\n",
    "- 추가적으로 gradient 문제를 해결 할 수 있도록 Layer Normalization도 추가해 볼 예정이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_ROOT = \"https://github.com/ageron/handson-ml2/raw/master/datasets/jsb_chorales/\"\n",
    "FILENAME = \"jsb_chorales.tgz\"\n",
    "filepath = keras.utils.get_file(FILENAME,\n",
    "                                DOWNLOAD_ROOT + FILENAME,\n",
    "                                cache_subdir=\"datasets/jsb_chorales\",\n",
    "                                extract=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\이지혜\\\\.keras\\\\datasets/jsb_chorales\\\\jsb_chorales.tgz'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "jsb_chorales_dir = pathlib.Path(filepath).parent\n",
    "train_files = sorted(jsb_chorales_dir.glob(\"train/chorale_*.csv\"))\n",
    "valid_files = sorted(jsb_chorales_dir.glob(\"valid/chorale_*.csv\"))\n",
    "test_files = sorted(jsb_chorales_dir.glob(\"test/chorale_*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_chorales(filepaths):\n",
    "    return [pd.read_csv(filepath).values.tolist() for filepath in filepaths]\n",
    "\n",
    "train_chorales = load_chorales(train_files)\n",
    "valid_chorales = load_chorales(valid_files)\n",
    "test_chorales = load_chorales(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[74, 70, 65, 58],\n",
       " [74, 70, 65, 58],\n",
       " [74, 70, 65, 58],\n",
       " [74, 70, 65, 58],\n",
       " [75, 70, 58, 55]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_chorales[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229, 76, 77)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_chorales), len(valid_chorales), len(test_chorales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192 \n",
      "228 \n",
      "208 \n",
      "432 \n",
      "260 \n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('%d ' %len(train_chorales[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = set()\n",
    "for steps in (train_chorales, test_chorales, valid_chorales):\n",
    "    for note in steps:\n",
    "        for i in note:\n",
    "             notes |= set(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_note, max_note = min(notes-{0}), max(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_note, max_note\n",
    "len_notes = len(notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    예측을 할때에 조금이라도 정확도를 높이기 위해서 아무 음표도 없다는 의미의 0을 제외하고 나머지 음표에 대한 최댓값과 최솟값을 구해 주었다. 따라서 나중에 훈련할 때에도 36과 81사이의 정수로 예측을 하도록 해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Prepare Dataset\n",
    "- 우선 모든 곡에 대한 timestep의 길이가 다르기 때문에 데이터를 tf.data.Dataset으로 바꾸려 할때에 ragged tensor이라 잘 변형이 되지 않았다.\n",
    "- 이렇게 입력 데이터가 4개의 음표로 나누어 있기 때문에 발생하는 현상인데, 그래서 그냥 sequence-to-sequence network를 이용하는 김에 입력 데이터로 지정해준 변수 window의 크기 만큼의 음표의 sequence를 제공해 주면 그것의 1step이후의, 똑같은 window크기 만큼 예측을 하는 것이다.\n",
    "    - 즉, (3,3+window크기) 만큼 준다면 4~4+window크기 만큼의 데이터를 예측하도록 하는 방법이다.\n",
    "- 그리고 모든 데이터의 크기의 범위를 0~46으로 바꿔주도록 했다.(나중의 Embedding Layer을 위해서)\n",
    "- 32개의 timestep, 즉 32 * 4 = 128개의 음표를 입력값으로 주어서 예측을 하도록 하였다.\n",
    "- 그리고 나중에는 tf.data.Dataset.from_tensor_slices()처리를 한 뒤에 shuffle과 batch_size를 이용해서 데이터셋을 만들었다.\n",
    "\n",
    "```tf.data.Dataset.Window()``` 함수는 입력데이터의 window 크기만큼 묶어서 dataset의 형태로 바꾸어 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target(data):\n",
    "    #x, 즉 입력 데이터는 전체 분할 데이터의 각각의 처음부터 끝의 하나 전까지, y는 각각의 두번째부터 끝까지\n",
    "    x = data[:,:-1]\n",
    "    y = data[:,1:]\n",
    "    return x,y\n",
    "\n",
    "#데이터의 범위를 0-46까지로 바꾸어 주기 위한 전처리용 함수\n",
    "def preprocess(data):\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[i])):\n",
    "            for k in range(len(data[i][j])):\n",
    "                if data[i][j][k] != 0:data[i][j][k] -= 35\n",
    "    return data\n",
    "\n",
    "#데이터중에 32개의 timestep을 하나의 긴 sequence로 바꿔야 하다 보니 각각의 window묶음에 대해서 reshaping을 해주어야 했다.\n",
    "#중요한 것은 이게 하나의 tensor의 형태로 바뀌었을 때에 tf.reshape를 해 줄 수가 없기 때문에(차원이 안맞음)\n",
    "#window로 나눠서 적용해야 해서 map()함수를 이용했다.\n",
    "def reshape(window):\n",
    "    #window, 즉 timestep을 32개 묶은 데이터를 하나의 데이터로 압축한다.\n",
    "    return tf.reshape(window, [-1])\n",
    "\n",
    "def make_sequence(dataset, batch_size = 32, shuffle = None, window_size = 32, window_shift = 16, cache = True):\n",
    "    def batch_window(window):\n",
    "        return window.batch(window_size + 1)\n",
    "    def to_window(dataset):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "        dataset = dataset.window(window_size + 1, window_shift, drop_remainder = True)\n",
    "        return dataset.flat_map(batch_window)\n",
    "    \n",
    "    dataset = preprocess(dataset)\n",
    "    dataset = tf.ragged.constant(dataset, ragged_rank = 1)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "    dataset = dataset.flat_map(to_window).map(reshape)\n",
    "    dataset = dataset.cache()\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(shuffle)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(make_target)\n",
    "    return dataset.prefetch(1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, None), (None, None)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = make_sequence(train_chorales, shuffle = 1000)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = make_sequence(test_chorales)\n",
    "val_data = make_sequence(valid_chorales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-1. Model 1 순환 모델\n",
    "**1. Customized RNN Cell**\n",
    "- 그냥 간단하게 RNN Cell의 작동 원리도 다시 공부해 볼 겸 새로운 RNN Cell을 직접 만들어 보았다.\n",
    "- 시퀀스가 긴 편이다 보니까 stacked RNN이 필요할 것 같았고, 따라서 하나의 RNN layer에 (tf.keras.layers.RNN)에 3개의 만든 RNN Cell을 넣어 주었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customRNNCell(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        #새롭게 RNN Cell을 만들고자 할 때에 중요한 것은 self.state_size 를 설정해 주어야 한다는 것이다.\n",
    "        #일반적으로 SimpleRNNCell은 input_size와 output_size의 unit의 개수가 동일해서 마친가지로 설정해 주었다.\n",
    "        self.units = units\n",
    "        self.state_size = units\n",
    "        self.output_size = units\n",
    "        super(customRNNCell, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        #새롭게 입력한 X(t)의 값에 주는 가중치의 행렬의 크기는 (입력 특성의 수, unit_size)\n",
    "        self.kernel = self.add_weight(shape = (input_shape[-1], self.units),initializer = 'uniform')\n",
    "        #이전 timestep의 출력값인 H(t-1)의 값에 주는 가중치의 행렬의 크기는 (unit_size, unit_size)\n",
    "        self.recurrent_kernel = self.add_weight(shape = (self.units, self.units), initializer = 'uniform')\n",
    "        self.built = True\n",
    "    \n",
    "    def call(self, inputs, states):\n",
    "        #states의 차원을 보면 \n",
    "        prev_outputs = states[0]\n",
    "        #keras.batckend.dot을 진행하면 행렬곱이 가능하지만 그러나 사실 tf.matmul()으로 바꾸어도 결과는 동일할 것이다.\n",
    "        #아래의 과정은 이전 단계에 가중치, 현재 입력 값에 가중치를 곱한 것이다.\n",
    "        new_outputs = tf.keras.backend.dot(inputs, self.kernel) + tf.keras.backend.dot(prev_outputs, self.recurrent_kernel)\n",
    "        return new_outputs, [new_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = [customRNNCell(units = 20), customRNNCell(units = 40)]\n",
    "layer = tf.keras.layers.RNN(cells)\n",
    "len_notes = len(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.keras.models.Sequential()\n",
    "model1.add(tf.keras.layers.Embedding(input_dim  = len_notes, output_dim = 20, input_shape = [None]))\n",
    "model1.add(tf.keras.layers.RNN(cells,return_sequences = True, input_shape = [None, 1]))\n",
    "model1.add(tf.keras.layers.RNN([customRNNCell(40),customRNNCell(80)], return_sequences = True))\n",
    "model1.add(tf.keras.layers.Dense(len_notes, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (None, None, 20)          940       \n",
      "_________________________________________________________________\n",
      "rnn_46 (RNN)                 (None, None, 40)          3200      \n",
      "_________________________________________________________________\n",
      "rnn_47 (RNN)                 (None, None, 80)          12800     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, None, 47)          3807      \n",
      "=================================================================\n",
      "Total params: 20,747\n",
      "Trainable params: 20,747\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**이 모델이 계속해서 fit을 하면 loss함수 때문에 문제가 생겼었다. 이는 내가 마지막 dense layer을 softmax로 설정해서 출력 차원이 47개인데 mean_squared_error로 loss를 계산하려 했기 때문이다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss = 'sparse_categorical_crossentropy', optimizer = tf.keras.optimizers.Nadam(learning_rate = 0.002), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "98/98 [==============================] - 16s 158ms/step - loss: 1.6156 - accuracy: 0.5055 - val_loss: 1.5885 - val_accuracy: 0.5142\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 19s 192ms/step - loss: 1.4851 - accuracy: 0.5695 - val_loss: 1.4377 - val_accuracy: 0.5979\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 19s 198ms/step - loss: 1.4114 - accuracy: 0.6152 - val_loss: 1.4083 - val_accuracy: 0.6261\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 21s 214ms/step - loss: 1.3562 - accuracy: 0.6486 - val_loss: 1.3479 - val_accuracy: 0.6572\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 20s 202ms/step - loss: 1.3017 - accuracy: 0.6812 - val_loss: 1.2992 - val_accuracy: 0.6769\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 21s 214ms/step - loss: 1.2723 - accuracy: 0.6924 - val_loss: 1.3067 - val_accuracy: 0.6773\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 21s 214ms/step - loss: 1.2295 - accuracy: 0.7050 - val_loss: 1.2204 - val_accuracy: 0.6990\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 21s 212ms/step - loss: 1.1934 - accuracy: 0.7141 - val_loss: 1.2122 - val_accuracy: 0.7030\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 21s 213ms/step - loss: 1.1599 - accuracy: 0.7171 - val_loss: 1.1933 - val_accuracy: 0.7011\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 21s 214ms/step - loss: 1.1188 - accuracy: 0.7194 - val_loss: 1.1140 - val_accuracy: 0.7168\n"
     ]
    }
   ],
   "source": [
    "hist1 = model1.fit(train_data, validation_data = val_data, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     34/Unknown - 1s 30ms/step - loss: 1.1699 - accuracy: 0.7011 1s 28ms/step"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.169853638200199, 0.70110965]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy = 70.11%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Customizationed Layer Normalization RNN Cell**\n",
    "- 우선 LSTM Layer을 첫번째 층에 사용하여서 단기 기억 소실을 방지하기 위해서 사용하였고\n",
    "- 기존에 사용하는 SimpleRNNCell에 대해서 Layer Normalization과 Dropout 기능을 추가한 새로운 cell을 custom하였는데, 모든 층에서 dropout을 하기 그래서 drop_val이라는 boolean 변수를 입력 받아 True이면 타임 스텝의 모든 은닉 상태에 대해서 dropout을 진행하게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormRNNCell(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, activation = 'tanh', **kwargs):\n",
    "        super(LayerNormRNNCell, self).__init__(**kwargs)\n",
    "        self.state_size = units\n",
    "        self.output_size = units\n",
    "        self.RNNCell = tf.keras.layers.SimpleRNNCell(units = units, activation = None)\n",
    "        self.output_norm = tf.keras.layers.LayerNormalization()\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "    \n",
    "    def call(self, input_x, states):\n",
    "        new_outputs, new_states = self.RNNCell(input_x, states)\n",
    "        new_outputs = self.activation(self.output_norm(new_outputs))\n",
    "        return new_outputs, [new_outputs]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.models.Sequential()\n",
    "model2.add(tf.keras.layers.Embedding(input_dim  = len_notes, output_dim = 5, input_shape = [None]))\n",
    "model2.add(tf.keras.layers.RNN(LayerNormRNNCell(units = 40),\n",
    "                               return_sequences = True,input_shape = [None, 1]))\n",
    "model2.add(tf.keras.layers.RNN(LayerNormRNNCell(units = 40),\n",
    "                               return_sequences = True))\n",
    "model2.add(tf.keras.layers.Dense(47, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 5)           235       \n",
      "_________________________________________________________________\n",
      "rnn_7 (RNN)                  (None, None, 40)          1920      \n",
      "_________________________________________________________________\n",
      "rnn_8 (RNN)                  (None, None, 40)          3320      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, None, 47)          1927      \n",
      "=================================================================\n",
      "Total params: 7,402\n",
      "Trainable params: 7,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "98/98 [==============================] - 28s 284ms/step - loss: 3.4851 - accuracy: 0.0691 - val_loss: 3.3959 - val_accuracy: 0.0743\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 27s 272ms/step - loss: 3.3489 - accuracy: 0.0868 - val_loss: 3.3269 - val_accuracy: 0.0986\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 27s 273ms/step - loss: 2.9329 - accuracy: 0.1407 - val_loss: 2.6742 - val_accuracy: 0.1422\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 27s 273ms/step - loss: 2.5909 - accuracy: 0.1695 - val_loss: 2.6065 - val_accuracy: 0.1644\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 27s 274ms/step - loss: 2.5650 - accuracy: 0.1764 - val_loss: 2.5862 - val_accuracy: 0.1742\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 27s 274ms/step - loss: 2.5445 - accuracy: 0.1812 - val_loss: 2.5557 - val_accuracy: 0.1632\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 27s 274ms/step - loss: 2.5140 - accuracy: 0.1925 - val_loss: 2.5302 - val_accuracy: 0.1823\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 28s 282ms/step - loss: 2.4042 - accuracy: 0.2181 - val_loss: 2.4167 - val_accuracy: 0.2197\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 27s 278ms/step - loss: 2.3456 - accuracy: 0.2394 - val_loss: 2.4566 - val_accuracy: 0.2329\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 27s 275ms/step - loss: 2.2730 - accuracy: 0.2706 - val_loss: 2.2715 - val_accuracy: 0.2769\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss = 'sparse_categorical_crossentropy', optimizer = tf.keras.optimizers.Nadam(learning_rate = 0.002), metrics = ['accuracy'])\n",
    "hist2 = model2.fit(train_data, validation_data = val_data, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     34/Unknown - 2s 53ms/step - loss: 2.2809 - accuracy: 0.2765"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2808691894306854, 0.27647611]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy - 6.97%**\n",
    "- 정확도가 터무니 없이 낮은데 아마 dropout을 추가해 줬기 때문 인것 같다.\n",
    "- 원래 Layer Normalization에 각 timestep마다 은닉층의 값에 dropout을 하는 방법으로 RNN cell을 만들었었는데, 그렇게 하니까 필요한 데이터가 다 dropout되는 듯 했다. \n",
    "- 그래서 그 부분을 빼고 오직 Layer Normalization의 기능만 추가해 주었으며, Embedding layer이후에 추가해 주었었던 LSTM layer또한 빼버렸다.  \n",
    "\n",
    "**New Accuracy = 27.65%**\n",
    "- 계속 학습을 시키면 더 정확도가 올라가겠지만 일단은 계속 정확도가 상승곡선이고 손실이 감소하기 때문에 만족스럽다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-2. Model 2- 합성곱 + 순환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Conv Layer + Recurrent Layer\n",
    "- 지금까지의 결과가 안좋았던 이유는 여러개가 있겠지만 무엇보다도 **Embedding Layer**을 추가해 주지 않았기 때문이 클 것이라고 생각한다.\n",
    "- 악보 또한 문자나 언어나 음성 등 처럼 일정한 연관성이 서로 있는데 그 부분을 고려해 주지 않으면 제대로 학습이 될 리가 없기 때문이다.\n",
    "- 따라서 처음에 Embeddding Layer을 추가해 주었고, Conv1D layer을 이용해서 학습을 해주다가 마지막에 LSTM과 Dense layer을 넣어 주었다.\n",
    "\n",
    "1. 악상간의 연관성을 따져주기 위해서 Embedding layer을 추가했고, Embedding layer의 input_dim은 총 사용된 음표의 종류의 개수이고, output_dim은 그냥 임의로 설정해 준 값이다. 이는 하나의 음표를 몇 차원으로 바꾸어 줄 것인지 설정한다.\n",
    "    - Embedding Layer은 모든 입력 데이터를 각각의 다른 벡터로 바꾸어 주는데, 이경우는 각각을 5차원 벡터로 바꾼 것이다.\n",
    "2. 이후에는 간단한 Wave Net을 구현하였다.\n",
    "3. 그리고 마지막에는 긴 장기 기억을 위해서 LSTM layer을 추가 하였다.\n",
    "4. 최종 Dense layer은 47개의 unit을 이용해서 출력을 하는데, 이유는 다음에 바로 나올 하나의 악상을 예측하는 것이며, 이를 47개중 하나로 출력하게 될 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 5)           235       \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 32)          352       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, None, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 48)          3120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, 48)          192       \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 64)          6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, None, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 96)          12384     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, None, 96)          384       \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, None, 256)         361472    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, None, 47)          12079     \n",
      "=================================================================\n",
      "Total params: 396,810\n",
      "Trainable params: 396,330\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_embedding_dims = 5\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(input_dim=len_notes, output_dim=n_embedding_dims,\n",
    "                           input_shape=[None]),\n",
    "    keras.layers.Conv1D(32, kernel_size=2, padding=\"causal\", activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv1D(48, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=2),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv1D(64, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=4),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv1D(96, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=8),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.LSTM(256, return_sequences=True),\n",
    "    keras.layers.Dense(len_notes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Nadam(learning_rate = 0.002)\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "98/98 [==============================] - 7s 72ms/step - loss: 1.4455 - accuracy: 0.6312 - val_loss: 3.6789 - val_accuracy: 0.0780\n",
      "Epoch 2/20\n",
      "98/98 [==============================] - 15s 158ms/step - loss: 0.7478 - accuracy: 0.7920 - val_loss: 4.0066 - val_accuracy: 0.1207\n",
      "Epoch 3/20\n",
      "98/98 [==============================] - 23s 233ms/step - loss: 0.6314 - accuracy: 0.8153 - val_loss: 3.5202 - val_accuracy: 0.1594\n",
      "Epoch 4/20\n",
      "98/98 [==============================] - 23s 232ms/step - loss: 0.5537 - accuracy: 0.8331 - val_loss: 2.9299 - val_accuracy: 0.2739\n",
      "Epoch 5/20\n",
      "98/98 [==============================] - 23s 231ms/step - loss: 0.5001 - accuracy: 0.8463 - val_loss: 2.1968 - val_accuracy: 0.4148\n",
      "Epoch 6/20\n",
      "98/98 [==============================] - 23s 231ms/step - loss: 0.4560 - accuracy: 0.8581 - val_loss: 0.7203 - val_accuracy: 0.7911\n",
      "Epoch 7/20\n",
      "98/98 [==============================] - 23s 232ms/step - loss: 0.4205 - accuracy: 0.8686 - val_loss: 0.6388 - val_accuracy: 0.8086\n",
      "Epoch 8/20\n",
      "98/98 [==============================] - 23s 231ms/step - loss: 0.3868 - accuracy: 0.8780 - val_loss: 0.6039 - val_accuracy: 0.8177\n",
      "Epoch 9/20\n",
      "98/98 [==============================] - 23s 231ms/step - loss: 0.3899 - accuracy: 0.8773 - val_loss: 0.7751 - val_accuracy: 0.7749\n",
      "Epoch 10/20\n",
      "98/98 [==============================] - 23s 231ms/step - loss: 0.3953 - accuracy: 0.8744 - val_loss: 0.6501 - val_accuracy: 0.8095\n",
      "Epoch 11/20\n",
      "98/98 [==============================] - 23s 231ms/step - loss: 0.3327 - accuracy: 0.8944 - val_loss: 0.5979 - val_accuracy: 0.8256\n",
      "Epoch 12/20\n",
      "98/98 [==============================] - 23s 231ms/step - loss: 0.3006 - accuracy: 0.9044 - val_loss: 0.6060 - val_accuracy: 0.8251\n",
      "Epoch 13/20\n",
      "98/98 [==============================] - 23s 231ms/step - loss: 0.2782 - accuracy: 0.9113 - val_loss: 0.6195 - val_accuracy: 0.8226\n",
      "Epoch 14/20\n",
      "98/98 [==============================] - 23s 231ms/step - loss: 0.2598 - accuracy: 0.9180 - val_loss: 1.0161 - val_accuracy: 0.7270\n",
      "Epoch 15/20\n",
      "98/98 [==============================] - 23s 231ms/step - loss: 0.3198 - accuracy: 0.8968 - val_loss: 0.6628 - val_accuracy: 0.8172\n",
      "Epoch 16/20\n",
      "98/98 [==============================] - 23s 231ms/step - loss: 0.2411 - accuracy: 0.9236 - val_loss: 0.6439 - val_accuracy: 0.8227\n",
      "Epoch 17/20\n",
      "98/98 [==============================] - 23s 231ms/step - loss: 0.2212 - accuracy: 0.9302 - val_loss: 0.7128 - val_accuracy: 0.8063\n",
      "Epoch 18/20\n",
      "98/98 [==============================] - 23s 231ms/step - loss: 0.2081 - accuracy: 0.9340 - val_loss: 0.6650 - val_accuracy: 0.8193\n",
      "Epoch 19/20\n",
      "98/98 [==============================] - 23s 231ms/step - loss: 0.1919 - accuracy: 0.9395 - val_loss: 0.7043 - val_accuracy: 0.8109\n",
      "Epoch 20/20\n",
      "98/98 [==============================] - 23s 231ms/step - loss: 0.1824 - accuracy: 0.9421 - val_loss: 0.6955 - val_accuracy: 0.8143\n"
     ]
    }
   ],
   "source": [
    "hist3 = model.fit(train_data, validation_data = val_data, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     34/Unknown - 1s 32ms/step - loss: 0.7045 - accuracy: 0.8156"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7044693073805641, 0.8156349]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy = 81.56%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (8,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(hist3.history['loss'], label = 'loss')\n",
    "plt.plot(hist3.history['val_loss'], label = 'val_loss')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(hist3.history['accuracy'], label = 'accuracy')\n",
    "plt.plot(hist3.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_chorale(model, seed_chord, length):\n",
    "    sound = tf.constant(seed_chord, dtype = tf.int64)\n",
    "    sound = tf.where(sound == 0, sound, sound - 35)\n",
    "    sound = tf.reshape(sound, [1,-1])\n",
    "    for i in range(length):\n",
    "        for j in range(4):\n",
    "            next_predict = model.predict_classes(sound)[:1, -1:]\n",
    "            sound = tf.concat([sound,next_predict], axis = 1)\n",
    "    sound = tf.where(sound == 0, sound, sound + 35)\n",
    "    return tf.reshape(sound, shape = [-1,4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
